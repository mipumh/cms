---
layout: post
title: 'Deepfakes: cómo los medios combaten la desinformación más sofisticada'
author: jaga
---
Ver es creer. Las grabaciones de vídeo y audio permiten que cualquiera se convierta en testigo de primera mano de un evento, lo que le ahorra la necesidad de decidir si confiar en el testimonio de otra persona. Gracias a los teléfonos inteligentes y las redes sociales, que permiten compartir y consumir esas grabaciones de forma masiva, las personas pueden confiar en sus propios ojos y oídos como si fueran notarios de la realidad. Sin embargo, en un mundo de mentiras cada vez más sofisticadas, ver ya no es creer. Los _deepfakes_, vídeos fabricados mediante modelos de Inteligencia Artificial, buscan generar polémica y manipular a la opinión pública. Ya son muchos los medios que trabajan para combatirlos.

Por el momento, en su mayoría son vídeos satíricos y fácilmente detectables. Tras las elecciones del 10-N, se difundió en las redes [un vídeo](https://www.youtube.com/watch?v=dj5M4s-cdAw) con _fakes_ de los cinco principales candidatos caracterizados como protagonistas del Equipo E, **una parodia del Equipo A que superó el millón de reproducciones en apenas 48 horas**. Los ejemplos de _deepfakes_ satíricos incluyen [los intercambios de caras](https://www.youtube.com/watch?v=5hZOcmqWKzY) entre el presidente Donald Trump y la canciller alemana Angela Merkel; entre el presidente argentino [Mauricio Macri y Adolf Hitler](https://www.youtube.com/watch?v=M8t6hGRtDac); y la falsificación de [unas declaraciones de Barak Obama](https://www.youtube.com/watch?v=gLoI9hAX9dw). Según un estudio de la consultora **Deeptrace**, en la red **actualmente circulan al menos 15.000 _deepfakes_ de todo tipo**.

![](/images/shots/1-deepfake-video.jpg)

Pero el asunto se vuelve más serio cuando se busca manipular a la opinión pública con _deepfakes_ que generan polémica, engañan e indignan a las masas. Imagina un vídeo que muestre al presidente Nicolás Maduro en una conversación privada con otro mandatario, en la que aparentemente revela un plan para llevar a cabo varios asesinatos políticos en Venezuela. O un clip de audio en el que dos generales norteamericanos diseñan una operación encubierta para matar a varios líderes palestinos radicales en el estrecho de Gaza. O un vídeo en el que se vea a un conocido político independentista catalán quemando una foto de Felipe VI. Se trata de grabaciones que tendrían un enorme potencial de agitación social, con consecuencias incalculables. Por ello, [el Pentágono norteamericano ya ha creado un programa para combatirlas](https://edition.cnn.com/interactive/2019/01/business/pentagons-race-against-deepfakes/). 

El deepfake es una técnica de inteligencia artificial que permite editar vídeos falsos que aparentemente parecen reales, utilizando algoritmos de aprendizaje no supervisados, conocidos como RGAs (Red Generativa Antagónica), a partir de grabaciones ya existentes. Este tipo de contenidos actualmente pueden elaborarse utilizando herramientas al alcance de cualquiera que disponga de un ordenador, acceso a internet y a una base de datos con imágenes de calidad. Las falsificaciones resultantes son tan convincentes que resulta imposible distinguirlas de las reales.

Los _deepfakes_ no se limitan a situaciones en las que el vídeo o el audio de eventos o declaraciones inexistentes tengan la apariencia de verdad. Imagina, por ejemplo, que una pieza con el estilo y el diseño de una noticia publicada en un medio se distribuye en las redes sociales y, al hacerlo, difunde un contenido falso como si fuera de ese medio. La pieza podría compartirse porque tiene la apariencia de un artículo publicado en el El País o el El Confidencial, por ejemplo, sin que ninguno de estos medios tuviera nada que ver. La falsedad no solo está en el contenido, sino **en la forma en que la pieza se disfraza como proveniente de una fuente periodística autorizada**.

![](/images/shots/2gif-obama.gif)

La preocupación ante este problema es global. El aumento de los vídeos ultrafalsos amenaza la erosión de las defensas institucionales contra la desinformación en el ámbito digital y plantea graves riesgos para la democracia y la seguridad. El entorno social ya sufre de desinformación y la distorsión de la verdad solo empeora a medida que los ciudadanos interactúan de manera tóxica, derivada de los sesgos cognitivos. Los  _deepfakes_ aumentarán la gravedad de este problema; los individuos y las empresas se enfrentarán a técnicas sofisticadas de explotación, intimidación y engaño. Sin embargo, aún queda mucho por investigar sobre los riesgos que afrontan los ciudadanos, las instituciones y la sociedad ante la actuación maliciosa de quienes emplean esta tecnología. 

El problema no es solo que se utilicen para avivar las divisiones sociales e ideológicas. También pueden facilitar que los mentirosos se justifiquen: conforme la sociedad se vuelve más consciente de la existencia de  _deepfakes_, los personajes públicos que aparecen en las grabaciones auténticas que muestran un comportamiento inapropiado podrán poner en duda la veracidad de esos vídeos. Además, a medida que los ciudadanos se sensibilizan ante la amenaza de los  _deepfakes_, tenderán a confiar menos en los medios y en las informaciones que les llegan. Y, por su parte, **los periodistas tendrán que actuar con mayor cautela al publicar audios o vídeos sobre acontecimientos de última hora**, tales como manifestaciones o atentados, por temor a que las imágenes hayan sido falsificadas.

Aunque el trabajo de verificar una información mediante el contraste de múltiples fuentes es algo básico en el periodismo, las técnicas se han vuelto más sofisticadas a medida que crece el acceso a nuevas herramientas de verificación digital. Los periodistas _fact-checkers_ trabajan como auténticos “detectives digitales” para luchar contra los  _deepfakes_ y las imágenes falsificadas. Veamos algunos casos:

* Los profesionales de **The New York Times** utilizaron técnicas de trabajo “forense" para confirmar la fecha, la hora y la ubicación [de un ataque con armas químicas en Siria](https://www.nytimes.com/2017/05/01/insider/the-times-uses-forensic-mapping-to-verify-a-syrian-chemical-attack.html?_r=0) mediante el análisis de información de Google Earth, videos de aficionados, cuentas de testigos oculares y una aplicación de movimiento solar, SunCalc. La información resultante desacreditó las afirmaciones de los líderes políticos rusos y sirios. El equipo de investigaciones visuales del periódico utilizó tácticas similares para construir una línea de tiempo de video detallada de la masacre provocada por un tiroteo en Las Vegas. 
* Reporteros de **ProPublica** y **Frontline** [investigaron horas de vídeo y miles de datos de publicaciones en redes sociales](https://www.propublica.org/article/michael-miselis-rise-above-movement-white-supremacist-group-northrop-grumman) para identificar a un miembro de un grupo violento de supremacistas blancos, que tenía una autorización de seguridad nacional por su trabajo con un contratista de defensa. Un día después de la publicación de la investigación, el contratista Northrop Grumman despidió a ese empleado. 
* En 2017, la **BBC** creó un equipo de verificación, [Reality Check,](https://www.bbc.com/news/reality_check) ante la ingente cantidad de material falso y  _deepfakes_ que necesitaban comprobar. En septiembre de 2018, los periodistas lograron verificar con sofisticadas técnicas de geolocalización, la procedencia de un vídeo[ que mostraba el asesinato de mujeres y niños a manos de soldados en Camerún](https://www.poynter.org/fact-checking/2018/how-the-bbc-verified-that-video-of-a-grisly-murder-in-cameroon-step-by-step/), y evidenciaron la veracidad de su contenido, frente al escepticismo de las autoridades del país.
* En junio de 2019, la **Unidad de Fact Checking** del **Washington Pos**t publicó [una excelente guía sobre cómo detectar vídeos manipulados y _deepfakes_](https://www.washingtonpost.com/graphics/2019/politics/fact-checker/manipulated-video-guide/). Sus recomendaciones cubren tres grandes áreas: falta de contexto, edición engañosa y transformación maliciosa, con numerosos consejos prácticos.
* **The Wall Street Journal** ha dado un paso decisivo con la creación de [una unidad especializada en combatir _deepfakes_](https://www.niemanlab.org/2018/11/how-the-wall-street-journal-is-preparing-its-journalists-to-detect-deepfakes/) en noviembre de 2018. La unidad, liderada por **Francesco Marconi**, ha establecido un protocolo de trabajo que incluye la verificación de las fuentes, la búsqueda de imágenes previas, el análisis de las grabaciones y la detección de irregularidades tales como la asincronía del audio, la alteración del entorno o la modificación digital. Precisamente están incorporando herramientas de Inteligencia Artificial para detectar estos vídeos falsos.

![](/images/shots/3-gif-deep-fakes.gif)

[Como explica en Retina **Raúl Arrabales**,](https://retina.elpais.com/retina/2018/09/17/innovacion/1537177382_367863.html) experto en Inteligencia Artificial, los propios algoritmos de _deep learning_ pueden usarse para detectar  _deepfakes_ de forma automática e incluso para generar “falsificaciones de laboratorio” que sirvan como entrenamiento para detectores de vídeos, imágenes y documentos falsos. De esta forma se podrán bloquear dichos contenidos o, al menos, advertir al consumidor de que está viendo un vídeo generado por ordenador. Para crear  _deepfakes_ de momento **hace falta disponer de un amplio volumen de material previo sobre la persona objeto de la manipulación**. Por eso se han fabricado sobre políticos como Obama o Trump, porque existe un archivo inmenso de grabaciones de sus discursos que facilita la tarea. 

Sin embargo, [los algoritmos de detección de  _deepfakes_ siguen yendo por detrás de la tecnología usada para generarlos](https://www.xataka.com/inteligencia-artificial/ha-comenzado-carrera-para-crear-tecnologia-capaz-detectar-deepfakes-falsificadores-llevan-ventaja). Los actores malintencionados actúan mucho más rápidamente que quienes quieren detenerlos, de modo que los  _deepfakes_ resultan cada vez más difíciles de detectar. En **Silicon Valley**, [varias tecnológicas llevan tiempo trabajando](https://www.latimes.com/politics/story/2019-11-05/deep-fakes-2020-election-silicon-valley-cure) para contrarrestar los efectos perversos de estas herramientas. Por su parte, [**Google y Facebook** ya han creado una base de datos ](https://elpais.com/tecnologia/2019/10/29/actualidad/1572343240_676009.html)con miles de archivos audiovisuales manipulados para entrenar herramientas de detección automática.

![](/images/shots/4-deep-fakes-zukeberg.jpeg)

Varios expertos reivindican la necesidad de implantar un programa intensivo de alfabetización mediática desde la educación secundaria que aborde estas cuestiones. Algunas iniciativas, como [este manual sobre “Periodismo, noticias falsas y desinfomación” ](https://es.unesco.org/sites/default/files/journalism_fake_news_disinformation_print_friendly_0.pdf)publicado por la **UNESCO**, contiene directrices muy útiles para verificar contenidos y luchar contra la desinformación. El manual propone cuestiones básicas, como: 

\- ¿Hay fallos e inconsistencias en el vídeo o en el audio?

\- ¿Confías en la fuente?

\- ¿Puedes encontrar otras imágenes que corroboren el contenido del video?

\- ¿Cómo se puede examinar la ubicación geográfica, la fecha de la grabación, la geolocalización y todo tipo de metadatos?

Nuestra experiencia de lo que sucede en el mundo y nuestra capacidad para tomar decisiones al respecto depende de que la información a la que accedemos sea veraz. Cuando se difunden masivamente contenidos falsos que se hacen pasar por auténticos, **el riesgo de manipulación es muy elevado, con perversas consecuencias en la opinión pública**. El problema que plantean los  _deepfakes_ y otras técnicas sofisticadas de desinformación es de qué modo los legisladores y las instituciones pueden preservar el derecho a la información veraz y restringir las técnicas de manipulación de contenidos sin entrar en conflicto con la libertad de expresión y sin ejercer un control contraproducente en internet. Medios y periodistas comparten la responsabilidad de combatir la desinformación generada por estos vídeos cada vez mejor elaborados, **con objeto de salvaguardar la calidad del debate en las sociedades democráticas**.
