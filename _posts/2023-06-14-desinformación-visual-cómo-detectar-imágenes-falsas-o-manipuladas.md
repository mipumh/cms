---
layout: post
title: "Desinformación visual: cómo detectar imágenes falsas o manipuladas"
---
![](https://lh3.googleusercontent.com/Nw98NTYkvFPkFnohwHr1l5EoPrE9tMdJmco-iM_cDrRhew38T8FtedhFObiyDM5dZws52MK0bluUwPKoxGCvSEtLTnLZW8B-sbE0EJreZK1oMbJ_MJ2RCQ75yOSldtFAkOWUgD8kQEOhd4iese6iumLh2Nk80hkfp_zbQrW51dM3upSC12kZBr8G_hjxH16Y)

Imagen generada con Bing Image Creator

Los contenidos audiovisuales se han convertido en el foco de gran parte de las estrategias de desinformación actuales. La aparición de herramientas de edición cada vez más sofisticadas, unida a los continuos avances en las técnicas de inteligencia artificial generativa, han dado lugar a **un escenario comunicativo en el que se cuestiona la autenticidad y veracidad de lo que vemos**. En los últimos meses hemos sido testigos de [una oleada de imágenes falsas](https://www.newtral.es/bulos-imagenes-inteligencia-artificial/20230327/) sin precedentes, difundidas en las redes sociales. Por suerte, algunas herramientas y trucos pueden ayudarte a detectarlas, como explicamos en este artículo.

### Imágenes manipuladas o descontextualizadas 

La búsqueda inversa de imágenes es una potente herramienta para detectar fotografías manipuladas o descontextualizadas. Esta técnica permite **buscar imágenes en línea utilizando un archivo como consulta en vez de palabras clave**. La mayoría de los buscadores, como [Google Imágenes](https://images.google.com/) o [Yandex Images](https://yandex.com/images/), ofrecen esta posibilidad aunque existen herramientas específicas que permiten acotar y perfeccionar la búsqueda:

[TinEye](https://tineye.com/). Empresa de búsqueda y reconocimiento de imágenes especializada en visión artíficial, reconocimiento de patrones, redes neuronales y aprendizaje automático. Surgió como un simple archivo de imágenes y se ha convertido en una potente herramienta de verificación. Su [API TinEye](https://services.tineye.com/TinEyeAPI) analiza más de 60 millones de imágenes en tiempo real, facilitando la **detección de imágenes manipuladas e infracciones de los derechos de autor**. Algunas de sus funcionalidades más interesantes son [TinEye Alerts](https://services.tineye.com/TinEyeAlerts), un sistema de seguimiento que detecta cuando ciertas imágenes aparecen online, y [MatchEngine](https://services.tineye.com/MatchEngine), centrado en la detección de contenido duplicado o modificado. Cuenta con una extensión para Chrome, Firefox, Edge y Opera.

[InVid Project](https://www.invid-project.eu/). Se trata de un conjunto de aplicaciones que permiten detectar, autenticar y comprobar la fiabilidad y exactitud de **archivos de vídeo e imágenes difundidas a través de las redes sociales**. El proyecto, en el que participan universidades, medios de comunicación y empresas tecnológicas de diferentes regiones de Europa, tiene como objetivo ofrecer una “navaja suiza” de verificación con el objetivo de **ahorrar tiempo y trabajar de forma más eficiente en las tareas de verificación**. Actualmente cuentan con una [versión web](https://www.invid-project.eu/invid-verification-application/), una [extensión de Chrome](https://chrome.google.com/webstore/detail/fake-news-debunker-by-inv/mhccpoafgdgbhnjfhkcmgknndkeenfhe?hl=en) y una [aplicación móvil](https://www.invid-project.eu/invid-mobile-application/) disponible para iOS y Android. Las técnicas de verificación empleadas están basadas en el libro “Verification Handbook”, un manual de verificación elaborado por expertos y periodistas de la BBC, Storyful, ABC y Digital First Media, entre otros. Puedes descargar su **versión en español** [aquí](https://verificationhandbook.com/downloads/manual.de.verificacion.pdf). 

![](https://lh4.googleusercontent.com/Tf0GdQ57zjzWE3sJJhviF_t72KQX3tt-b92zW5A_ZdO80ZJ9NVxldTPSkAHFiJ1me5whyhzWFyJiQh_nn0D0AatIRWAt0YsaeYj9B9TwC4476tcpEVm-A7LBBICONSkmkFKSPBNDwOz7xr2B7sqrrut-KhJ6dHNPq5Mlk2otDgMIXp-FniS8KLYFJCCNXBoL)

[Foresincally](https://29a.ch/photo-forensics/#clone-detection). Una herramienta más compleja, pero también más completa que otras alternativas similares. Basada en técnicas de “investigación forense” de imágenes, permite **detectar retoques digitales** mediante funcionalidades como el análisis de ruido, la detección de zonas “clonadas”, los cambios en la iluminación y el acceso a los metadatos e información de geolocalización. Puedes consultar un videotutorial de manos de su creador [aquí](https://www.youtube.com/watch?v=XRCq8CJrI_s&ab_channel=JonasWagner). 

[Verification Toolbox](https://firstdraftnews.org/verification-toolbox/) de FirstDraftNews. Una sencilla herramienta web que permite **investigar el origen de las imágenes y vídeos alojados en redes sociales** como YouTube, Twitter o Facebook. Aunque el proyecto FirstDraftNews cesó su actividad en 2022, cuenta con numerosos **recursos de monitorización, verificación y alfabetización mediática** que merece la pena conocer. Entre ellos, su sección de “[mini cursos](https://firstdraftnews.org/bucket/our-training/)” online, y las guías “[Cómo verificar información encontrada en línea](https://firstdraftnews.org/wp-content/uploads/2020/07/Verifying_Online_Information_Digital_AW_ES.pdf?x21167)” y “[Comprender el desorden informativo](https://firstdraftnews.org/wp-content/uploads/2020/07/Information_Disorder_Digital_AW_ES.pdf?x21167)”. 

[Get-Metadata](https://www.get-metadata.com/) y [ExtractMetada](http://www.extractmetadata.com/es.html). A menudo encontramos imágenes en línea que, pese a no estar manipuladas, en realidad no muestran aquello que nos quieren hacer creer. En estos casos, analizar la ubicación y fecha en la que se tomó la fotografía suele ser una buena solución. Las herramientas gratuitas Get-Metadata y ExtractMetada sirven para **comprobar los metadatos de imágenes, vídeos, documentos, audios** y, en el caso de Get-Metadata, incluso e-books. Su funcionamiento es muy sencillo: tan solo tienes que subir el archivo o indicar su url y esperar. El programa te mostrará todos los datos asociados gracias a la información XMP, EXIF e ICC.

### El peligro de los *deepfakes* y las imáganes generadas con IA

En el blog hemos analizado los retos que supone la proliferación de *[deepfakes](https://mip.umh.es/blog/2019/12/01/deepfakes-c%C3%B3mo-los-medios-combaten-la-desinformaci%C3%B3n-m%C3%A1s-sofisticada/)*, una de las estrategias de desinformación más sofisticadas. Se trata de una técnica mediante inteligencia artificial que emplea algoritmos de aprendizaje automático y redes neuronales para **alterar o reemplazar el rostro y la voz de una persona a partir de un vídeo existente**. Mediante el uso de grandes cantidades de imágenes y vídeos de la persona que se desea imitar, esta tecnología **permite crear contenido audiovisual manipulado sumamente realista y convincente**. Una de las principales preocupaciones es, precisamente, su enorme potencial dañino a la hora de crear contenido falso para desacreditar figuras públicas o simular discursos políticos con un gran realismo. 

En 2021, la EUROPOL ya alertaba de los **riesgos que supone un mal uso de la inteligencia artificial**, en especial en lo que respecta a la creación de contenido audiovisual. En su informe “[Malicious Uses and Abuses of Artificial Intelligence](https://www.europol.europa.eu/cms/sites/default/files/documents/malicious_uses_and_abuses_of_artificial_intelligence_europol.pdf)”, elaborado junto al Instituto Interregional de Investigación sobre Justicia y Crimen de las Naciones Unidas (UNICRI), definen a los *deepfakes* como “un arma poderosa en las guerras de desinformación actuales”, ya que **abren un nuevo paradigma en el que ya no se puede confiar en lo que se ve o se escucha.** 

`<iframe width="560" height="315" src="https://www.youtube.com/embed/AmUC4m6w1wo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>`

Sin embargo, **la inteligencia artificial también puede ser la solución** para frenar el avance de los contenidos manipulados. La compañía estadounidense Intel, en una parte de su proyecto [Trusted Media](https://www.intel.com/content/www/us/en/research/blogs/trusted-media.html), incorporó en uno de sus procesadores la tecnología de detección de *deepfakes* desarrollada por el investigador Ilke Demir y el profesor de la Universidad Estatal de Nueva York, Binghamton Umur Ciftci. Esta tecnología, llamada **FakeCatcher**, utiliza técnicas de fotopletismografía en busca de “señales biológicas” (como el flujo sanguíneo de la piel) para determinar si quien aparece en la imagen es una persona real o está generada de forma virtual. Los investigadores aseguran obtener resultados superiores al 90% en todos los datasets empleados [en el estudio](https://ieeexplore.ieee.org/document/9141516). 

Otra iniciativa similar es el proyecto **DepthFake**, llevado a cabo por un grupo de investigación de la Sapienza Università di Roma. En este caso, los investigadores **combinan las técnicas tradicionales de análisis del color con los [mapas de profundidad](https://www.xatakafoto.com/software/asi-funciona-esta-inteligencia-artificial-que-analiza-genera-mapas-profundidad-fotografias)** para detectar inconsistencias en las imágenes. Mientras que los mapas de profundidad proporcionan información tridimensional sobre una escena, las imágenes RGB ofrecen información acerca del color. Al combinar estas dos fuentes de datos, **los algoritmos de detección analizan las características y anomalías específicas que pueden revelar la presencia de una imagen falsa o manipulada**. Por ejemplo, mediante cambios en la iluminación, la consistencia espacial o las distorsiones en la perspectiva. 

Sin embargo, aunque ambas técnicas facilitan el proceso y son clave a la hora de analizar un gran volumen de datos, **algunos trucos pueden ayudarnos a detectar *deepfakes*** de manera más “tradicional”. Los expertos coinciden en que, cuando entra en juego la inteligencia artificial, **la respuesta está en los detalles**. Los ojos son el primer elemento a tener en cuenta. El número de parpadeos y la forma en que lo hace (a menudo forzada y poco natural), pueden darnos una pista de que algo anda mal. Otro detalle importante es el interior de la boca. **Las tecnologías de creación de *deepfakes* tienen problemas a la hora de reproducir la lengua y los dientes** cuando la persona está hablando. Las texturas, el número y la forma de los dientes, son otro aspecto clave. Además, si la persona es famosa, podemos fijarnos en otros detalles como la desaparición o aparición de lunares, líneas de expresión o vello facial poco realista. 

¿Y qué ocurre con las **fotografías generadas mediante inteligencia artificial**? Eso nos daría para otro artículo. Por ahora, aquí van algunas pinceladas. Al igual que sucedió con los *deepfakes*, la reciente oleada de fotografías generadas con IA plantea nuevos retos, dudas e incertidumbres. Mientras diversos organismos e instituciones internacionales debaten sobre cuál es la mejor forma de proceder, numerosos expertos en el ámbito de la verificación comienzan a publicar **guías y pautas para ayudar a la sociedad a detectar este tipo de imágenes**. En español, son especialmente valiosas las propuestas de [Maldita](https://maldita.es/malditatecnologia/20230512/consejos-detectar-imagenes-inteligencia-artificial-dalle/), [Newtral](https://www.newtral.es/como-detectar-imagenes-videos-audios-deepfakes-generados-ia/20230331/) y [Chequeado](https://chequeado.com/ultimas-noticias/como-saber-si-una-imagen-fue-creada-con-inteligencia-artificial/). 



Este artículo es el resultado de la colaboración de la investigadora Alba García Ortega en el [proyecto europeo IBERIFIER](https://iberifier.eu/), un observatorio financiado por la Comisión Europea para la investigación sobre el ecosistema mediático y la lucha contra la desinformación en España y Portugal.

![](https://lh4.googleusercontent.com/bTs6FgRTnThLnwCt1k9znNteTi7m0wTzKMw0vlWQ0jgExP-Fa2RBSrXICKLBuLQOIbFdYLod-VXFKHgK1o_akO8iKO2Iw7H0wqL-_l26kIWq4SblFtm-_ijwNoH04mgmHmwej_wDb9liGgB9o9Lwxkm1C6aOQnBGBUKqUK0YXcdKqnsbcMK9rqCsQ_BG9lPx)